{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45d5ce33",
   "metadata": {},
   "source": [
    "# NYC Motor Vehicle Collision Injury Prediction Pipeline\n",
    "\n",
    "This notebook implements a reproducible data pipeline that predicts whether a NYC collision results in any injuries or fatalities.\n",
    "\n",
    "**Research Question:** Given collision context (time, location, vehicle types, contributing factors), can we predict if a crash will cause at least one injury or fatality?\n",
    "\n",
    "## Section 1: Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95bb35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn - preprocessing and pipelines\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Sklearn - models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Sklearn - evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69682653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Raw data: Motor_Vehicle_Collisions_-_Crashes_20251202.csv\n",
      "  Database: collisions.db\n",
      "  Train years: 2012-2024\n",
      "  Test year: 2025\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "db_url = os.getenv(\"FILE_PATH\")\n",
    "# File paths\n",
    "RAW_DATA_PATH = db_url\n",
    "DB_PATH = \"collisions.db\"\n",
    "\n",
    "# Train/test split configuration (time-based)\n",
    "TRAIN_YEARS = list(range(2012, 2025))  # 2012-2024\n",
    "TEST_YEAR = 2025\n",
    "\n",
    "# Feature configuration\n",
    "CATEGORICAL_FEATURES = [\n",
    "    'borough',\n",
    "    'hour',\n",
    "    'day_of_week', \n",
    "    'is_weekend',\n",
    "    'is_rush_hour',\n",
    "    'vehicle_type_1',\n",
    "    'contributing_factor_1'\n",
    "]\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "    'num_vehicles'\n",
    "]\n",
    "\n",
    "TARGET = 'severe'\n",
    "\n",
    "# Vehicle type consolidation mapping (raw values → standardized categories)\n",
    "VEHICLE_TYPE_MAP = {\n",
    "    # Sedan/Passenger\n",
    "    'Sedan': 'Sedan', '4 dr sedan': 'Sedan', '2 dr sedan': 'Sedan',\n",
    "    'PASSENGER VEHICLE': 'Sedan', '3-Door': 'Sedan',\n",
    "    # SUV/Station Wagon\n",
    "    'Station Wagon/Sport Utility Vehicle': 'SUV', \n",
    "    'SPORT UTILITY / STATION WAGON': 'SUV',\n",
    "    # Taxi\n",
    "    'Taxi': 'Taxi', 'TAXI': 'Taxi', 'Livery Vehicle': 'Taxi',\n",
    "    # Truck\n",
    "    'Pick-up Truck': 'Truck', 'Box Truck': 'Truck', \n",
    "    'LARGE COM VEH(6 OR MORE TIRES)': 'Truck', 'Tractor Truck Diesel': 'Truck',\n",
    "    'Flat Bed': 'Truck', 'Dump': 'Truck', 'Tow Truck / Wrecker': 'Truck',\n",
    "    # Van\n",
    "    'VAN': 'Van', 'Van': 'Van', 'AMBULANCE': 'Van',\n",
    "    # Bus\n",
    "    'Bus': 'Bus', 'BUS': 'Bus',\n",
    "    # Motorcycle\n",
    "    'Motorcycle': 'Motorcycle', 'MOTORCYCLE': 'Motorcycle', 'Motorbike': 'Motorcycle',\n",
    "    # Bike\n",
    "    'Bike': 'Bike', 'E-Bike': 'Bike', 'E-Scooter': 'Bike',\n",
    "    # Other/Unknown\n",
    "    'OTHER': 'Other', 'UNKNOWN': 'Unknown', 'Unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "# Contributing factor consolidation mapping\n",
    "CONTRIBUTING_FACTOR_MAP = {\n",
    "    'Driver Inattention/Distraction': 'Distraction',\n",
    "    'Failure to Yield Right-of-Way': 'Failure to Yield',\n",
    "    'Following Too Closely': 'Following Too Closely',\n",
    "    'Backing Unsafely': 'Improper Maneuver',\n",
    "    'Passing or Lane Usage Improper': 'Improper Maneuver',\n",
    "    'Passing Too Closely': 'Improper Maneuver',\n",
    "    'Turning Improperly': 'Improper Maneuver',\n",
    "    'Unsafe Lane Changing': 'Improper Maneuver',\n",
    "    'Fatigued/Drowsy': 'Fatigue',\n",
    "    'Traffic Control Disregarded': 'Traffic Violation',\n",
    "    'Unsafe Speed': 'Speeding',\n",
    "    'Alcohol Involvement': 'Alcohol/Drugs',\n",
    "    'Drugs (illegal)': 'Alcohol/Drugs',\n",
    "    'Driver Inexperience': 'Inexperience',\n",
    "    'Unspecified': 'Unspecified',\n",
    "    'Other Vehicular': 'Other'\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Raw data: {RAW_DATA_PATH}\")\n",
    "print(f\"  Database: {DB_PATH}\")\n",
    "print(f\"  Train years: {TRAIN_YEARS[0]}-{TRAIN_YEARS[-1]}\")\n",
    "print(f\"  Test year: {TEST_YEAR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d68c91",
   "metadata": {},
   "source": [
    "## Section 2: Data Loading and Cleaning\n",
    "\n",
    "Load the raw CSV, parse dates, handle missing values, and create the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3ff38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2,224,642 rows × 29 columns\n",
      "\n",
      "Columns: ['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE', 'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME', 'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5', 'COLLISION_ID', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5']\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "df_raw = pd.read_csv(RAW_DATA_PATH, low_memory=False)\n",
    "\n",
    "print(f\"Loaded {len(df_raw):,} rows × {len(df_raw.columns)} columns\")\n",
    "print(f\"\\nColumns: {list(df_raw.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f56cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete!\n",
      "  Rows: 2,224,642\n",
      "  Date range: 2012-07-01 to 2025-11-29\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA CLEANING\n",
    "# =============================================================================\n",
    "\n",
    "df = df_raw.copy()\n",
    "\n",
    "# 1. Parse date and time\n",
    "df['crash_datetime'] = pd.to_datetime(\n",
    "    df['CRASH DATE'] + ' ' + df['CRASH TIME'], \n",
    "    format='%m/%d/%Y %H:%M'\n",
    ")\n",
    "df['year'] = df['crash_datetime'].dt.year\n",
    "\n",
    "# 2. Handle missing values\n",
    "# Borough and ZIP Code: preserve NULLs for KNN imputation (will fill with \"Unknown\" after imputation)\n",
    "df['borough'] = df['BOROUGH']\n",
    "df['zip_code'] = df['ZIP CODE'].astype(str).replace('nan', np.nan)  # Convert string 'nan' to actual NaN\n",
    "\n",
    "# Coordinates: create flag for missing\n",
    "df['coords_missing'] = df['LATITUDE'].isna() | df['LONGITUDE'].isna()\n",
    "df['latitude'] = df['LATITUDE']\n",
    "df['longitude'] = df['LONGITUDE']\n",
    "\n",
    "# Contributing factors: fill with \"Unknown\"\n",
    "for i in range(1, 6):\n",
    "    col = f'CONTRIBUTING FACTOR VEHICLE {i}'\n",
    "    df[f'contributing_factor_{i}'] = df[col].fillna('Unknown') if col in df.columns else 'Unknown'\n",
    "\n",
    "# Vehicle types: fill with \"Unknown\"\n",
    "for i in range(1, 6):\n",
    "    col = f'VEHICLE TYPE CODE {i}'\n",
    "    df[f'vehicle_type_{i}'] = df[col].fillna('Unknown') if col in df.columns else 'Unknown'\n",
    "\n",
    "# 3. Create target variable: SEVERE = 1 if any injury or fatality\n",
    "df['num_injured'] = df['NUMBER OF PERSONS INJURED'].fillna(0)\n",
    "df['num_killed'] = df['NUMBER OF PERSONS KILLED'].fillna(0)\n",
    "df['severe'] = ((df['num_injured'] + df['num_killed']) > 0).astype(int)\n",
    "\n",
    "# 4. Keep collision ID\n",
    "df['collision_id'] = df['COLLISION_ID']\n",
    "\n",
    "print(\"Data cleaning complete!\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Date range: {df['crash_datetime'].min().strftime('%Y-%m-%d')} to {df['crash_datetime'].max().strftime('%Y-%m-%d')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54cbc7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATION: After Data Cleaning\n",
      "======================================================================\n",
      "\n",
      "Dataset Overview:\n",
      "  Total rows: 2,224,642\n",
      "  Total columns: 50\n",
      "\n",
      "Missing Data Summary:\n",
      "  borough         | Missing:  681,099 ( 30.6%)\n",
      "  zip_code        | Missing:  681,376 ( 30.6%)\n",
      "  latitude        | Missing:  240,389 ( 10.8%)\n",
      "  longitude       | Missing:  240,389 ( 10.8%)\n",
      "  coords_missing  | Missing:  240,389 ( 10.8%)\n",
      "\n",
      "Borough Distribution:\n",
      "  NULL                 |  681,099 ( 30.6%)\n",
      "  BROOKLYN             |  494,784 ( 22.2%)\n",
      "  QUEENS               |  413,609 ( 18.6%)\n",
      "  MANHATTAN            |  341,956 ( 15.4%)\n",
      "  BRONX                |  228,562 ( 10.3%)\n",
      "  STATEN ISLAND        |   64,632 (  2.9%)\n",
      "\n",
      "Top Contributing Factors (Vehicle 1):\n",
      "  Unspecified                              |  744,354 ( 33.5%)\n",
      "  Driver Inattention/Distraction           |  451,764 ( 20.3%)\n",
      "  Failure to Yield Right-of-Way            |  133,292 (  6.0%)\n",
      "  Following Too Closely                    |  119,471 (  5.4%)\n",
      "  Backing Unsafely                         |   81,174 (  3.6%)\n",
      "  Other Vehicular                          |   69,554 (  3.1%)\n",
      "  Passing or Lane Usage Improper           |   63,878 (  2.9%)\n",
      "  Passing Too Closely                      |   56,537 (  2.5%)\n",
      "  Turning Improperly                       |   54,731 (  2.5%)\n",
      "  Fatigued/Drowsy                          |   47,559 (  2.1%)\n",
      "\n",
      "Top Contributing Factors (Vehicle 2):\n",
      "  Unspecified                              | 1,570,976 ( 70.6%)\n",
      "  Unknown                                  |  357,584 ( 16.1%)\n",
      "  Driver Inattention/Distraction           |  101,005 (  4.5%)\n",
      "  Other Vehicular                          |   34,227 (  1.5%)\n",
      "  Following Too Closely                    |   20,844 (  0.9%)\n",
      "  Failure to Yield Right-of-Way            |   18,050 (  0.8%)\n",
      "  Passing or Lane Usage Improper           |   13,899 (  0.6%)\n",
      "  Fatigued/Drowsy                          |   10,848 (  0.5%)\n",
      "  Passing Too Closely                      |    9,396 (  0.4%)\n",
      "  Turning Improperly                       |    9,118 (  0.4%)\n",
      "\n",
      "Top Vehicle Types (Vehicle 1):\n",
      "  Sedan                                    |  643,745 ( 28.9%)\n",
      "  Station Wagon/Sport Utility Vehicle      |  504,073 ( 22.7%)\n",
      "  PASSENGER VEHICLE                        |  416,206 ( 18.7%)\n",
      "  SPORT UTILITY / STATION WAGON            |  180,291 (  8.1%)\n",
      "  Taxi                                     |   55,968 (  2.5%)\n",
      "  4 dr sedan                               |   40,187 (  1.8%)\n",
      "  Pick-up Truck                            |   38,341 (  1.7%)\n",
      "  TAXI                                     |   31,911 (  1.4%)\n",
      "  Box Truck                                |   26,608 (  1.2%)\n",
      "  VAN                                      |   25,266 (  1.1%)\n",
      "\n",
      "Top Vehicle Types (Vehicle 2):\n",
      "  Unknown                                  |  447,086 ( 20.1%)\n",
      "  Sedan                                    |  442,119 ( 19.9%)\n",
      "  Station Wagon/Sport Utility Vehicle      |  355,639 ( 16.0%)\n",
      "  PASSENGER VEHICLE                        |  318,607 ( 14.3%)\n",
      "  SPORT UTILITY / STATION WAGON            |  140,204 (  6.3%)\n",
      "  UNKNOWN                                  |   81,546 (  3.7%)\n",
      "  Taxi                                     |   39,263 (  1.8%)\n",
      "  Bike                                     |   38,342 (  1.7%)\n",
      "  Pick-up Truck                            |   34,205 (  1.5%)\n",
      "  Box Truck                                |   31,266 (  1.4%)\n",
      "\n",
      "Target Variable (severe):\n",
      "  No Injury            (0) | 1,682,159 ( 75.6%)\n",
      "  Injury/Fatal         (1) |  542,483 ( 24.4%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VALIDATION CHECK: After Data Cleaning\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VALIDATION: After Data Cleaning\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Total columns: {len(df.columns)}\")\n",
    "\n",
    "# Missing data analysis\n",
    "print(f\"\\nMissing Data Summary:\")\n",
    "missing_cols = ['borough', 'zip_code', 'latitude', 'longitude']\n",
    "for col in missing_cols:\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isna().sum()\n",
    "        missing_pct = (missing_count / len(df)) * 100\n",
    "        print(f\"  {col:15} | Missing: {missing_count:>8,} ({missing_pct:>5.1f}%)\")\n",
    "\n",
    "# Coordinates status\n",
    "if 'coords_missing' in df.columns:\n",
    "    missing_coords = df['coords_missing'].sum()\n",
    "    print(f\"  {'coords_missing':15} | Missing: {missing_coords:>8,} ({(missing_coords/len(df)*100):>5.1f}%)\")\n",
    "\n",
    "# Borough distribution\n",
    "print(f\"\\nBorough Distribution:\")\n",
    "if 'borough' in df.columns:\n",
    "    borough_counts = df['borough'].value_counts(dropna=False)\n",
    "    for borough, count in borough_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        borough_display = str(borough) if not pd.isna(borough) else 'NULL'\n",
    "        print(f\"  {borough_display:20} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# Leading Contributing Factors\n",
    "print(f\"\\nTop Contributing Factors (Vehicle 1):\")\n",
    "if 'contributing_factor_1' in df.columns:\n",
    "    cf1_counts = df['contributing_factor_1'].value_counts()\n",
    "    for factor, count in cf1_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(factor):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTop Contributing Factors (Vehicle 2):\")\n",
    "if 'contributing_factor_2' in df.columns:\n",
    "    cf2_counts = df['contributing_factor_2'].value_counts()\n",
    "    for factor, count in cf2_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(factor):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# Leading Vehicle Types\n",
    "print(f\"\\nTop Vehicle Types (Vehicle 1):\")\n",
    "if 'vehicle_type_1' in df.columns:\n",
    "    vt1_counts = df['vehicle_type_1'].value_counts()\n",
    "    for vtype, count in vt1_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(vtype):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTop Vehicle Types (Vehicle 2):\")\n",
    "if 'vehicle_type_2' in df.columns:\n",
    "    vt2_counts = df['vehicle_type_2'].value_counts()\n",
    "    for vtype, count in vt2_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(vtype):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# Target variable distribution\n",
    "print(f\"\\nTarget Variable (severe):\")\n",
    "if 'severe' in df.columns:\n",
    "    severe_counts = df['severe'].value_counts()\n",
    "    for val, count in severe_counts.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        label = \"Injury/Fatal\" if val == 1 else \"No Injury\"\n",
    "        print(f\"  {label:20} ({val}) | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdcb1ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "KNN SPATIAL VOTING IMPUTATION\n",
      "======================================================================\n",
      "Known locations (has lat, lon, borough, zip): 1,505,519\n",
      "Missing location labels (has lat, lon, missing borough/zip): 478,734\n",
      "\n",
      "Fitting KNN model (k=50) on 1,505,519 known locations...\n",
      "Finding neighbors for 478,734 missing location labels...\n",
      "Performing spatial voting imputation...\n",
      "\n",
      "======================================================================\n",
      "IMPUTATION VALIDATION\n",
      "======================================================================\n",
      "\n",
      "Rows with coordinates: 1,984,253\n",
      "\n",
      "Boroughs:\n",
      "  Filled via KNN: 478,734\n",
      "  Remaining 'Unknown': 202,616 (9.1%)\n",
      "\n",
      "Zip Codes:\n",
      "  Filled via KNN: 478,734\n",
      "  Remaining 'Unknown': 202,642 (9.1%)\n",
      "\n",
      "======================================================================\n",
      "SANITY CHECK: Sample of 10 Imputed Rows with 5 Nearest Neighbors\n",
      "======================================================================\n",
      "\n",
      "Imputed Row (collision_id=3849576):\n",
      "  Location: (40.68195, -73.89652)\n",
      "  Imputed Borough: BROOKLYN\n",
      "  Imputed Zip: 11207\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11207 | Coords: (40.68195, -73.89652)\n",
      "    2. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11207 | Coords: (40.68195, -73.89652)\n",
      "    3. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11207 | Coords: (40.68195, -73.89652)\n",
      "    4. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11207 | Coords: (40.68195, -73.89652)\n",
      "    5. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11207 | Coords: (40.68195, -73.89652)\n",
      "\n",
      "Imputed Row (collision_id=3405239):\n",
      "  Location: (40.68158, -73.73734)\n",
      "  Imputed Borough: QUEENS\n",
      "  Imputed Zip: 11413\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: QUEENS | Zip: 11413 | Coords: (40.68158, -73.73734)\n",
      "    2. Distance: 0.00011 | Borough: QUEENS | Zip: 11413 | Coords: (40.68167, -73.73740)\n",
      "    3. Distance: 0.00011 | Borough: QUEENS | Zip: 11413 | Coords: (40.68167, -73.73740)\n",
      "    4. Distance: 0.00011 | Borough: QUEENS | Zip: 11413 | Coords: (40.68167, -73.73740)\n",
      "    5. Distance: 0.00011 | Borough: QUEENS | Zip: 11413 | Coords: (40.68167, -73.73740)\n",
      "\n",
      "Imputed Row (collision_id=2864982):\n",
      "  Location: (40.80522, -73.93213)\n",
      "  Imputed Borough: MANHATTAN\n",
      "  Imputed Zip: 10035\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10035 | Coords: (40.80522, -73.93213)\n",
      "    2. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10035 | Coords: (40.80522, -73.93213)\n",
      "    3. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10035 | Coords: (40.80522, -73.93213)\n",
      "    4. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10035 | Coords: (40.80522, -73.93213)\n",
      "    5. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10035 | Coords: (40.80522, -73.93213)\n",
      "\n",
      "Imputed Row (collision_id=4418459):\n",
      "  Location: (40.81691, -73.93401)\n",
      "  Imputed Borough: MANHATTAN\n",
      "  Imputed Zip: 10037\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10037 | Coords: (40.81691, -73.93401)\n",
      "    2. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10037 | Coords: (40.81691, -73.93401)\n",
      "    3. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10037 | Coords: (40.81691, -73.93401)\n",
      "    4. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10037 | Coords: (40.81691, -73.93401)\n",
      "    5. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10037 | Coords: (40.81691, -73.93401)\n",
      "\n",
      "Imputed Row (collision_id=3526169):\n",
      "  Location: (40.58993, -74.14568)\n",
      "  Imputed Borough: STATEN ISLAND\n",
      "  Imputed Zip: 10314\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10314 | Coords: (40.58993, -74.14568)\n",
      "    2. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10314 | Coords: (40.58993, -74.14568)\n",
      "    3. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10314 | Coords: (40.58993, -74.14568)\n",
      "    4. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10314 | Coords: (40.58993, -74.14568)\n",
      "    5. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10314 | Coords: (40.58993, -74.14568)\n",
      "\n",
      "Imputed Row (collision_id=3522404):\n",
      "  Location: (40.80442, -73.95538)\n",
      "  Imputed Borough: MANHATTAN\n",
      "  Imputed Zip: 10026\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10026 | Coords: (40.80442, -73.95538)\n",
      "    2. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10026 | Coords: (40.80442, -73.95538)\n",
      "    3. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10026 | Coords: (40.80442, -73.95538)\n",
      "    4. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10026 | Coords: (40.80442, -73.95538)\n",
      "    5. Distance: 0.00000 | Borough: MANHATTAN | Zip: 10026 | Coords: (40.80442, -73.95538)\n",
      "\n",
      "Imputed Row (collision_id=4219329):\n",
      "  Location: (40.71437, -73.74680)\n",
      "  Imputed Borough: QUEENS\n",
      "  Imputed Zip: 11429\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: QUEENS | Zip: 11429 | Coords: (40.71437, -73.74680)\n",
      "    2. Distance: 0.00000 | Borough: QUEENS | Zip: 11429 | Coords: (40.71437, -73.74680)\n",
      "    3. Distance: 0.00000 | Borough: QUEENS | Zip: 11429 | Coords: (40.71437, -73.74680)\n",
      "    4. Distance: 0.00000 | Borough: QUEENS | Zip: 11429 | Coords: (40.71437, -73.74680)\n",
      "    5. Distance: 0.00000 | Borough: QUEENS | Zip: 11429 | Coords: (40.71437, -73.74680)\n",
      "\n",
      "Imputed Row (collision_id=4002089):\n",
      "  Location: (40.69246, -73.72688)\n",
      "  Imputed Borough: QUEENS\n",
      "  Imputed Zip: 11411\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: QUEENS | Zip: 11411 | Coords: (40.69246, -73.72688)\n",
      "    2. Distance: 0.00000 | Borough: QUEENS | Zip: 11411 | Coords: (40.69246, -73.72688)\n",
      "    3. Distance: 0.00000 | Borough: QUEENS | Zip: 11411 | Coords: (40.69246, -73.72688)\n",
      "    4. Distance: 0.00000 | Borough: QUEENS | Zip: 11411 | Coords: (40.69246, -73.72688)\n",
      "    5. Distance: 0.00000 | Borough: QUEENS | Zip: 11411 | Coords: (40.69246, -73.72688)\n",
      "\n",
      "Imputed Row (collision_id=3123573):\n",
      "  Location: (40.61051, -74.09575)\n",
      "  Imputed Borough: STATEN ISLAND\n",
      "  Imputed Zip: 10304\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10304 | Coords: (40.61051, -74.09575)\n",
      "    2. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10304 | Coords: (40.61051, -74.09575)\n",
      "    3. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10304 | Coords: (40.61051, -74.09575)\n",
      "    4. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10304 | Coords: (40.61051, -74.09575)\n",
      "    5. Distance: 0.00000 | Borough: STATEN ISLAND | Zip: 10304 | Coords: (40.61051, -74.09575)\n",
      "\n",
      "Imputed Row (collision_id=4380597):\n",
      "  Location: (40.67582, -73.93047)\n",
      "  Imputed Borough: BROOKLYN\n",
      "  Imputed Zip: 11233\n",
      "  5 Nearest Neighbors:\n",
      "    1. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11233 | Coords: (40.67582, -73.93047)\n",
      "    2. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11233 | Coords: (40.67582, -73.93047)\n",
      "    3. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11233 | Coords: (40.67582, -73.93047)\n",
      "    4. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11233 | Coords: (40.67582, -73.93047)\n",
      "    5. Distance: 0.00000 | Borough: BROOKLYN | Zip: 11233 | Coords: (40.67582, -73.93047)\n",
      "\n",
      "======================================================================\n",
      "KNN IMPUTATION COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BOROUGH & ZIP_CODE IMPUTATION (KNN SPATIAL VOTING)\n",
    "# =============================================================================\n",
    "\n",
    "def impute_location_labels_knn(df, k=50, min_neighbors=10):\n",
    "    \"\"\"\n",
    "    Impute missing borough and zip_code using K-Nearest Neighbors spatial voting.\n",
    "    \n",
    "    Strategy:\n",
    "    - Split data into known_locations (has lat, lon, borough, zip) and \n",
    "      missing_location_labels (has lat, lon but missing borough and/or zip)\n",
    "    - Use KNN to find k nearest known neighbors for each missing row\n",
    "    - Assign borough = mode(neighbor boroughs), zip_code = mode(neighbor zip_codes)\n",
    "    - If < min_neighbors found, mark as \"Unknown\"\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'latitude', 'longitude', 'borough', 'zip_code', 'collision_id'\n",
    "        k: Number of nearest neighbors to consider (default: 50)\n",
    "        min_neighbors: Minimum neighbors required for imputation (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with imputed borough/zip_code and 'imputation_method' column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create boolean masks for missing coordinates\n",
    "    has_coords = df['latitude'].notna() & df['longitude'].notna()\n",
    "    \n",
    "    # Split into known and missing location labels\n",
    "    # Known: has coordinates AND both borough and zip_code are non-null\n",
    "    known_mask = (\n",
    "        has_coords & \n",
    "        df['borough'].notna() & \n",
    "        df['zip_code'].notna() &\n",
    "        (df['zip_code'] != 'nan')  # Also exclude string 'nan'\n",
    "    )\n",
    "    \n",
    "    # Missing labels: has coordinates BUT missing borough and/or zip_code\n",
    "    missing_mask = (\n",
    "        has_coords & \n",
    "        (df['borough'].isna() | df['zip_code'].isna() | (df['zip_code'] == 'nan'))\n",
    "    )\n",
    "    \n",
    "    known_locations = df[known_mask].copy()\n",
    "    missing_location_labels = df[missing_mask].copy()\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"KNN SPATIAL VOTING IMPUTATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Known locations (has lat, lon, borough, zip): {len(known_locations):,}\")\n",
    "    print(f\"Missing location labels (has lat, lon, missing borough/zip): {len(missing_location_labels):,}\")\n",
    "    \n",
    "    if len(known_locations) == 0:\n",
    "        print(\"WARNING: No known locations found. Cannot perform imputation.\")\n",
    "        df['imputation_method'] = None\n",
    "        return df\n",
    "    \n",
    "    if len(missing_location_labels) == 0:\n",
    "        print(\"No missing location labels to impute.\")\n",
    "        df['imputation_method'] = None\n",
    "        return df\n",
    "    \n",
    "    # Prepare coordinates for KNN\n",
    "    # Use Euclidean distance on lat/lon (acceptable for NYC-scale distances)\n",
    "    known_coords = known_locations[['latitude', 'longitude']].values\n",
    "    missing_coords = missing_location_labels[['latitude', 'longitude']].values\n",
    "    \n",
    "    # Fit KNN model on known locations\n",
    "    print(f\"\\nFitting KNN model (k={k}) on {len(known_coords):,} known locations...\")\n",
    "    nn = NearestNeighbors(n_neighbors=min(k, len(known_locations)), metric='euclidean', n_jobs=-1)\n",
    "    nn.fit(known_coords)\n",
    "    \n",
    "    # Find neighbors for missing locations (vectorized)\n",
    "    print(f\"Finding neighbors for {len(missing_coords):,} missing location labels...\")\n",
    "    distances, indices = nn.kneighbors(missing_coords)\n",
    "    \n",
    "    # Initialize imputation method column\n",
    "    df['imputation_method'] = None\n",
    "    \n",
    "    # Vectorized imputation using mode voting\n",
    "    print(\"Performing spatial voting imputation...\")\n",
    "    \n",
    "    # Get indices of missing rows in original dataframe\n",
    "    missing_indices = missing_location_labels.index.values\n",
    "    \n",
    "    # For each missing row, get its neighbors and compute mode\n",
    "    imputed_borough = []\n",
    "    imputed_zip = []\n",
    "    imputed_method = []\n",
    "    \n",
    "    for i, missing_idx in enumerate(missing_indices):\n",
    "        neighbor_indices = indices[i]\n",
    "        n_neighbors = len(neighbor_indices)\n",
    "        \n",
    "        if n_neighbors < min_neighbors:\n",
    "            # Not enough neighbors - mark as Unknown\n",
    "            imputed_borough.append('Unknown')\n",
    "            imputed_zip.append('Unknown')\n",
    "            imputed_method.append(None)\n",
    "        else:\n",
    "            # Get neighbor boroughs and zip codes\n",
    "            neighbor_df_indices = known_locations.index[neighbor_indices]\n",
    "            neighbor_boroughs = df.loc[neighbor_df_indices, 'borough'].values\n",
    "            neighbor_zips = df.loc[neighbor_df_indices, 'zip_code'].values\n",
    "            \n",
    "            # Remove any NaN values from neighbors\n",
    "            neighbor_boroughs = neighbor_boroughs[~pd.isna(neighbor_boroughs)]\n",
    "            neighbor_zips = neighbor_zips[~pd.isna(neighbor_zips)]\n",
    "            neighbor_zips = neighbor_zips[neighbor_zips != 'nan']\n",
    "            \n",
    "            # Compute mode (most frequent value)\n",
    "            if len(neighbor_boroughs) > 0:\n",
    "                borough_mode = pd.Series(neighbor_boroughs).mode()\n",
    "                imputed_borough_val = borough_mode.iloc[0] if len(borough_mode) > 0 else 'Unknown'\n",
    "            else:\n",
    "                imputed_borough_val = 'Unknown'\n",
    "            \n",
    "            if len(neighbor_zips) > 0:\n",
    "                zip_mode = pd.Series(neighbor_zips).mode()\n",
    "                imputed_zip_val = zip_mode.iloc[0] if len(zip_mode) > 0 else 'Unknown'\n",
    "            else:\n",
    "                imputed_zip_val = 'Unknown'\n",
    "            \n",
    "            # Only impute if original value is missing (check for NULLs only)\n",
    "            original_borough = df.loc[missing_idx, 'borough']\n",
    "            original_zip = df.loc[missing_idx, 'zip_code']\n",
    "            \n",
    "            # Check if borough needs imputation\n",
    "            borough_needs_imputation = pd.isna(original_borough)\n",
    "            if borough_needs_imputation:\n",
    "                imputed_borough.append(imputed_borough_val)\n",
    "            else:\n",
    "                imputed_borough.append(original_borough)\n",
    "            \n",
    "            # Check if zip_code needs imputation (handle both NULL and string 'nan')\n",
    "            zip_needs_imputation = pd.isna(original_zip) or (isinstance(original_zip, str) and original_zip == 'nan')\n",
    "            if zip_needs_imputation:\n",
    "                imputed_zip.append(imputed_zip_val)\n",
    "            else:\n",
    "                imputed_zip.append(original_zip)\n",
    "            \n",
    "            # Mark method if we actually imputed something\n",
    "            if borough_needs_imputation or zip_needs_imputation:\n",
    "                imputed_method.append('knn_spatial_vote')\n",
    "            else:\n",
    "                imputed_method.append(None)\n",
    "    \n",
    "    # Update dataframe with imputed values\n",
    "    df.loc[missing_indices, 'borough'] = imputed_borough\n",
    "    df.loc[missing_indices, 'zip_code'] = imputed_zip\n",
    "    df.loc[missing_indices, 'imputation_method'] = imputed_method\n",
    "    \n",
    "    # Fill remaining NULLs with \"Unknown\"\n",
    "    df['borough'] = df['borough'].fillna('Unknown')\n",
    "    df['zip_code'] = df['zip_code'].fillna('Unknown').astype(str)\n",
    "    df['zip_code'] = df['zip_code'].replace('nan', 'Unknown')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply KNN imputation\n",
    "df = impute_location_labels_knn(df, k=50, min_neighbors=10)\n",
    "\n",
    "# Validation output\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"IMPUTATION VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Count imputed rows\n",
    "imputed_mask = df['imputation_method'] == 'knn_spatial_vote'\n",
    "n_imputed = imputed_mask.sum()\n",
    "\n",
    "# Count remaining \"Unknown\" boroughs and zip codes\n",
    "n_unknown_borough = (df['borough'] == 'Unknown').sum()\n",
    "n_unknown_zip = (df['zip_code'] == 'Unknown').sum()\n",
    "\n",
    "# Count original missing (before imputation would have been)\n",
    "has_coords = df['latitude'].notna() & df['longitude'].notna()\n",
    "n_with_coords = has_coords.sum()\n",
    "\n",
    "print(f\"\\nRows with coordinates: {n_with_coords:,}\")\n",
    "print(f\"\\nBoroughs:\")\n",
    "print(f\"  Filled via KNN: {n_imputed:,}\")\n",
    "print(f\"  Remaining 'Unknown': {n_unknown_borough:,} ({n_unknown_borough/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nZip Codes:\")\n",
    "print(f\"  Filled via KNN: {n_imputed:,}\")\n",
    "print(f\"  Remaining 'Unknown': {n_unknown_zip:,} ({n_unknown_zip/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Sanity check: Show random sample of imputed rows with their neighbors\n",
    "if n_imputed > 0:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SANITY CHECK: Sample of 10 Imputed Rows with 5 Nearest Neighbors\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    imputed_rows = df[imputed_mask].sample(min(10, n_imputed), random_state=42)\n",
    "    \n",
    "    # For each imputed row, show its 5 nearest neighbors\n",
    "    known_mask = (\n",
    "        df['latitude'].notna() & \n",
    "        df['longitude'].notna() & \n",
    "        df['borough'].notna() & \n",
    "        df['zip_code'].notna() &\n",
    "        (df['zip_code'] != 'nan') &\n",
    "        (df['zip_code'] != 'Unknown')\n",
    "    )\n",
    "    known_locations = df[known_mask]\n",
    "    known_coords = known_locations[['latitude', 'longitude']].values\n",
    "    \n",
    "    nn_sample = NearestNeighbors(n_neighbors=5, metric='euclidean')\n",
    "    nn_sample.fit(known_coords)\n",
    "    \n",
    "    for idx, row in imputed_rows.iterrows():\n",
    "        print(f\"\\nImputed Row (collision_id={row['collision_id']}):\")\n",
    "        print(f\"  Location: ({row['latitude']:.5f}, {row['longitude']:.5f})\")\n",
    "        print(f\"  Imputed Borough: {row['borough']}\")\n",
    "        print(f\"  Imputed Zip: {row['zip_code']}\")\n",
    "        \n",
    "        # Find 5 nearest neighbors\n",
    "        query_coord = [[row['latitude'], row['longitude']]]\n",
    "        distances, neighbor_indices = nn_sample.kneighbors(query_coord)\n",
    "        \n",
    "        print(f\"  5 Nearest Neighbors:\")\n",
    "        for j, (dist, neighbor_idx) in enumerate(zip(distances[0], neighbor_indices[0])):\n",
    "            neighbor_row = known_locations.iloc[neighbor_idx]\n",
    "            print(f\"    {j+1}. Distance: {dist:.5f} | \"\n",
    "                  f\"Borough: {neighbor_row['borough']} | \"\n",
    "                  f\"Zip: {neighbor_row['zip_code']} | \"\n",
    "                  f\"Coords: ({neighbor_row['latitude']:.5f}, {neighbor_row['longitude']:.5f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KNN IMPUTATION COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff660a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1e0be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDATION SUMMARY\n",
      "============================================================\n",
      "\n",
      "1. TARGET DISTRIBUTION:\n",
      "   No injury (0): 1,682,159 (75.6%)\n",
      "   Injury/fatal (1): 542,483 (24.4%)\n",
      "\n",
      "2. BOROUGH DISTRIBUTION:\n",
      "   BROOKLYN: 620,065 (27.9%)\n",
      "   QUEENS: 572,736 (25.7%)\n",
      "   MANHATTAN: 425,263 (19.1%)\n",
      "   BRONX: 304,308 (13.7%)\n",
      "   Unknown: 202,616 (9.1%)\n",
      "   STATEN ISLAND: 99,654 (4.5%)\n",
      "\n",
      "3. YEAR DISTRIBUTION:\n",
      "   2012: 100,545\n",
      "   2013: 203,742\n",
      "   2014: 206,046\n",
      "   2015: 217,708\n",
      "   2016: 229,831\n",
      "   2017: 231,007\n",
      "   2018: 231,564\n",
      "   2019: 211,486\n",
      "   2020: 112,917\n",
      "   2021: 110,557\n",
      "   2022: 103,887\n",
      "   2023: 96,607\n",
      "   2024: 91,314\n",
      "   2025: 77,431\n",
      "\n",
      "4. COORDINATES:\n",
      "   Missing: 240,389 (10.8%)\n",
      "\n",
      "5. NULL CHECK (key columns):\n",
      "   collision_id: 0 nulls\n",
      "   crash_datetime: 0 nulls\n",
      "   borough: 0 nulls\n",
      "   severe: 0 nulls\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VALIDATION CHECKS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Target distribution\n",
    "severe_counts = df['severe'].value_counts()\n",
    "print(f\"\\n1. TARGET DISTRIBUTION:\")\n",
    "print(f\"   No injury (0): {severe_counts[0]:,} ({severe_counts[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"   Injury/fatal (1): {severe_counts[1]:,} ({severe_counts[1]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Borough distribution\n",
    "print(f\"\\n2. BOROUGH DISTRIBUTION:\")\n",
    "for borough, count in df['borough'].value_counts().items():\n",
    "    print(f\"   {borough}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Year distribution  \n",
    "print(f\"\\n3. YEAR DISTRIBUTION:\")\n",
    "year_counts = df['year'].value_counts().sort_index()\n",
    "for year, count in year_counts.items():\n",
    "    print(f\"   {year}: {count:,}\")\n",
    "\n",
    "# Missing coordinates\n",
    "missing_coords = df['coords_missing'].sum()\n",
    "print(f\"\\n4. COORDINATES:\")\n",
    "print(f\"   Missing: {missing_coords:,} ({missing_coords/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Check for any remaining nulls in key columns\n",
    "key_cols = ['collision_id', 'crash_datetime', 'borough', 'severe']\n",
    "print(f\"\\n5. NULL CHECK (key columns):\")\n",
    "for col in key_cols:\n",
    "    nulls = df[col].isna().sum()\n",
    "    print(f\"   {col}: {nulls} nulls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d723dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate Imputation by Borough:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: divide by zero encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: overflow encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: invalid value encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:257: RuntimeWarning: divide by zero encountered in matmul\n",
      "  candidates_pot = distance_to_candidates @ sample_weight.reshape(-1, 1)\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:257: RuntimeWarning: overflow encountered in matmul\n",
      "  candidates_pot = distance_to_candidates @ sample_weight.reshape(-1, 1)\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:257: RuntimeWarning: invalid value encountered in matmul\n",
      "  candidates_pot = distance_to_candidates @ sample_weight.reshape(-1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BROOKLYN        | Valid: 609,670 | Imputed: 10,395 | k=406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: divide by zero encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: overflow encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: invalid value encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  BRONX           | Valid: 297,351 | Imputed:  6,957 | k=198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: divide by zero encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: overflow encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: invalid value encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MANHATTAN       | Valid: 415,182 | Imputed: 10,081 | k=276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: divide by zero encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: overflow encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: invalid value encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  QUEENS          | Valid: 564,041 | Imputed:  8,695 | k=376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: divide by zero encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: overflow encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n",
      "/Users/anime_shh/personalCS/data_mgmt/accident-tracker/venv/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:237: RuntimeWarning: invalid value encountered in matmul\n",
      "  current_pot = closest_dist_sq @ sample_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  STATEN ISLAND   | Valid:  98,009 | Imputed:  1,645 | k=65\n",
      "\n",
      "==================================================\n",
      "IMPUTATION SUMMARY\n",
      "==================================================\n",
      "  Coordinates imputed: 37,773\n",
      "  Still missing (Unknown borough): 202,616\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COORDINATE IMPUTATION (K-MEANS)\n",
    "# =============================================================================\n",
    "\n",
    "def impute_coordinates_kmeans(df, min_cluster_size=1500):\n",
    "    \"\"\"\n",
    "    Impute missing coordinates using K-means clustering per borough.\n",
    "    \n",
    "    For each borough:\n",
    "    - Fit K-means on rows with valid coordinates\n",
    "    - Assign borough centroid to rows with missing coordinates\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'borough', 'latitude', 'longitude', 'coords_missing' columns\n",
    "        min_cluster_size: Approximate rows per cluster (k = n_rows / min_cluster_size)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with imputed coordinates and 'coords_imputed' flag\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['coords_imputed'] = False\n",
    "    \n",
    "    # Get boroughs with valid coordinates (exclude \"Unknown\")\n",
    "    valid_boroughs = df[(df['coords_missing'] == False) & (df['borough'] != 'Unknown')]['borough'].unique()\n",
    "    \n",
    "    print(\"Coordinate Imputation by Borough:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for borough in valid_boroughs:\n",
    "        # Masks for this borough\n",
    "        mask_valid = (df['borough'] == borough) & (df['coords_missing'] == False)\n",
    "        mask_missing = (df['borough'] == borough) & (df['coords_missing'] == True)\n",
    "        \n",
    "        n_valid = mask_valid.sum()\n",
    "        n_missing = mask_missing.sum()\n",
    "        \n",
    "        if n_valid < 10 or n_missing == 0:\n",
    "            continue\n",
    "        \n",
    "        # Determine number of clusters\n",
    "        n_clusters = max(5, n_valid // min_cluster_size)\n",
    "        \n",
    "        # Fit K-means on valid coordinates\n",
    "        valid_coords = df.loc[mask_valid, ['latitude', 'longitude']].values\n",
    "        km = KMeans(n_clusters=n_clusters, random_state=42, n_init=5)\n",
    "        km.fit(valid_coords)\n",
    "        \n",
    "        # Compute borough centroid (mean of all valid coords)\n",
    "        borough_centroid = valid_coords.mean(axis=0)\n",
    "        \n",
    "        # Impute missing coords with borough centroid\n",
    "        df.loc[mask_missing, 'latitude'] = borough_centroid[0]\n",
    "        df.loc[mask_missing, 'longitude'] = borough_centroid[1]\n",
    "        df.loc[mask_missing, 'coords_imputed'] = True\n",
    "        df.loc[mask_missing, 'coords_missing'] = False\n",
    "        \n",
    "        print(f\"  {borough:15} | Valid: {n_valid:>7,} | Imputed: {n_missing:>6,} | k={n_clusters}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply imputation\n",
    "df = impute_coordinates_kmeans(df)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"IMPUTATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "total_imputed = df['coords_imputed'].sum()\n",
    "still_missing = df['coords_missing'].sum()\n",
    "print(f\"  Coordinates imputed: {total_imputed:,}\")\n",
    "print(f\"  Still missing (Unknown borough): {still_missing:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03cad680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "VALIDATION: After Location Imputation (KNN)\n",
      "======================================================================\n",
      "\n",
      "Dataset Overview:\n",
      "  Total rows: 2,224,642\n",
      "  Total columns: 52\n",
      "\n",
      "Missing Data Summary:\n",
      "  borough         | Missing:        0 (  0.0%)\n",
      "  zip_code        | Missing:        0 (  0.0%)\n",
      "  latitude        | Missing:  202,616 (  9.1%)\n",
      "  longitude       | Missing:  202,616 (  9.1%)\n",
      "  coords_missing  | Missing:  202,616 (  9.1%)\n",
      "\n",
      "Imputation Summary:\n",
      "  Rows imputed via KNN: 478,734 ( 21.5%)\n",
      "\n",
      "Borough Distribution (After Imputation):\n",
      "  BROOKLYN             |  620,065 ( 27.9%)\n",
      "  QUEENS               |  572,736 ( 25.7%)\n",
      "  MANHATTAN            |  425,263 ( 19.1%)\n",
      "  BRONX                |  304,308 ( 13.7%)\n",
      "  Unknown              |  202,616 (  9.1%)\n",
      "  STATEN ISLAND        |   99,654 (  4.5%)\n",
      "\n",
      "Top Contributing Factors (Vehicle 1):\n",
      "  Unspecified                              |  744,354 ( 33.5%)\n",
      "  Driver Inattention/Distraction           |  451,764 ( 20.3%)\n",
      "  Failure to Yield Right-of-Way            |  133,292 (  6.0%)\n",
      "  Following Too Closely                    |  119,471 (  5.4%)\n",
      "  Backing Unsafely                         |   81,174 (  3.6%)\n",
      "  Other Vehicular                          |   69,554 (  3.1%)\n",
      "  Passing or Lane Usage Improper           |   63,878 (  2.9%)\n",
      "  Passing Too Closely                      |   56,537 (  2.5%)\n",
      "  Turning Improperly                       |   54,731 (  2.5%)\n",
      "  Fatigued/Drowsy                          |   47,559 (  2.1%)\n",
      "\n",
      "Top Contributing Factors (Vehicle 2):\n",
      "  Unspecified                              | 1,570,976 ( 70.6%)\n",
      "  Unknown                                  |  357,584 ( 16.1%)\n",
      "  Driver Inattention/Distraction           |  101,005 (  4.5%)\n",
      "  Other Vehicular                          |   34,227 (  1.5%)\n",
      "  Following Too Closely                    |   20,844 (  0.9%)\n",
      "  Failure to Yield Right-of-Way            |   18,050 (  0.8%)\n",
      "  Passing or Lane Usage Improper           |   13,899 (  0.6%)\n",
      "  Fatigued/Drowsy                          |   10,848 (  0.5%)\n",
      "  Passing Too Closely                      |    9,396 (  0.4%)\n",
      "  Turning Improperly                       |    9,118 (  0.4%)\n",
      "\n",
      "Top Vehicle Types (Vehicle 1):\n",
      "  Sedan                                    |  643,745 ( 28.9%)\n",
      "  Station Wagon/Sport Utility Vehicle      |  504,073 ( 22.7%)\n",
      "  PASSENGER VEHICLE                        |  416,206 ( 18.7%)\n",
      "  SPORT UTILITY / STATION WAGON            |  180,291 (  8.1%)\n",
      "  Taxi                                     |   55,968 (  2.5%)\n",
      "  4 dr sedan                               |   40,187 (  1.8%)\n",
      "  Pick-up Truck                            |   38,341 (  1.7%)\n",
      "  TAXI                                     |   31,911 (  1.4%)\n",
      "  Box Truck                                |   26,608 (  1.2%)\n",
      "  VAN                                      |   25,266 (  1.1%)\n",
      "\n",
      "Top Vehicle Types (Vehicle 2):\n",
      "  Unknown                                  |  447,086 ( 20.1%)\n",
      "  Sedan                                    |  442,119 ( 19.9%)\n",
      "  Station Wagon/Sport Utility Vehicle      |  355,639 ( 16.0%)\n",
      "  PASSENGER VEHICLE                        |  318,607 ( 14.3%)\n",
      "  SPORT UTILITY / STATION WAGON            |  140,204 (  6.3%)\n",
      "  UNKNOWN                                  |   81,546 (  3.7%)\n",
      "  Taxi                                     |   39,263 (  1.8%)\n",
      "  Bike                                     |   38,342 (  1.7%)\n",
      "  Pick-up Truck                            |   34,205 (  1.5%)\n",
      "  Box Truck                                |   31,266 (  1.4%)\n",
      "\n",
      "Target Variable (severe):\n",
      "  No Injury            (0) | 1,682,159 ( 75.6%)\n",
      "  Injury/Fatal         (1) |  542,483 ( 24.4%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VALIDATION CHECK: After Location Imputation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"VALIDATION: After Location Imputation (KNN)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"  Total rows: {len(df):,}\")\n",
    "print(f\"  Total columns: {len(df.columns)}\")\n",
    "\n",
    "# Missing data analysis\n",
    "print(f\"\\nMissing Data Summary:\")\n",
    "missing_cols = ['borough', 'zip_code', 'latitude', 'longitude']\n",
    "for col in missing_cols:\n",
    "    if col in df.columns:\n",
    "        missing_count = df[col].isna().sum()\n",
    "        missing_pct = (missing_count / len(df)) * 100\n",
    "        print(f\"  {col:15} | Missing: {missing_count:>8,} ({missing_pct:>5.1f}%)\")\n",
    "\n",
    "# Coordinates status\n",
    "if 'coords_missing' in df.columns:\n",
    "    missing_coords = df['coords_missing'].sum()\n",
    "    print(f\"  {'coords_missing':15} | Missing: {missing_coords:>8,} ({(missing_coords/len(df)*100):>5.1f}%)\")\n",
    "\n",
    "# Imputation method summary\n",
    "if 'imputation_method' in df.columns:\n",
    "    imputed_count = (df['imputation_method'] == 'knn_spatial_vote').sum()\n",
    "    print(f\"\\nImputation Summary:\")\n",
    "    print(f\"  Rows imputed via KNN: {imputed_count:,} ({(imputed_count/len(df)*100):>5.1f}%)\")\n",
    "\n",
    "# Borough distribution (after imputation)\n",
    "print(f\"\\nBorough Distribution (After Imputation):\")\n",
    "if 'borough' in df.columns:\n",
    "    borough_counts = df['borough'].value_counts(dropna=False)\n",
    "    for borough, count in borough_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        borough_display = str(borough) if not pd.isna(borough) else 'NULL'\n",
    "        print(f\"  {borough_display:20} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# Leading Contributing Factors\n",
    "print(f\"\\nTop Contributing Factors (Vehicle 1):\")\n",
    "if 'contributing_factor_1' in df.columns:\n",
    "    cf1_counts = df['contributing_factor_1'].value_counts()\n",
    "    for factor, count in cf1_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(factor):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTop Contributing Factors (Vehicle 2):\")\n",
    "if 'contributing_factor_2' in df.columns:\n",
    "    cf2_counts = df['contributing_factor_2'].value_counts()\n",
    "    for factor, count in cf2_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(factor):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# Leading Vehicle Types\n",
    "print(f\"\\nTop Vehicle Types (Vehicle 1):\")\n",
    "if 'vehicle_type_1' in df.columns:\n",
    "    vt1_counts = df['vehicle_type_1'].value_counts()\n",
    "    for vtype, count in vt1_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(vtype):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nTop Vehicle Types (Vehicle 2):\")\n",
    "if 'vehicle_type_2' in df.columns:\n",
    "    vt2_counts = df['vehicle_type_2'].value_counts()\n",
    "    for vtype, count in vt2_counts.head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {str(vtype):40} | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "# Target variable distribution\n",
    "print(f\"\\nTarget Variable (severe):\")\n",
    "if 'severe' in df.columns:\n",
    "    severe_counts = df['severe'].value_counts()\n",
    "    for val, count in severe_counts.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        label = \"Injury/Fatal\" if val == 1 else \"No Injury\"\n",
    "        print(f\"  {label:20} ({val}) | {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff8560d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset: 2,224,642 rows × 22 columns\n",
      "\n",
      "Columns: ['collision_id', 'crash_datetime', 'year', 'borough', 'zip_code', 'latitude', 'longitude', 'coords_missing', 'coords_imputed', 'num_injured', 'num_killed', 'severe', 'vehicle_type_1', 'vehicle_type_2', 'vehicle_type_3', 'vehicle_type_4', 'vehicle_type_5', 'contributing_factor_1', 'contributing_factor_2', 'contributing_factor_3', 'contributing_factor_4', 'contributing_factor_5']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collision_id</th>\n",
       "      <th>crash_datetime</th>\n",
       "      <th>year</th>\n",
       "      <th>borough</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>coords_missing</th>\n",
       "      <th>coords_imputed</th>\n",
       "      <th>num_injured</th>\n",
       "      <th>num_killed</th>\n",
       "      <th>severe</th>\n",
       "      <th>vehicle_type_1</th>\n",
       "      <th>vehicle_type_2</th>\n",
       "      <th>vehicle_type_3</th>\n",
       "      <th>vehicle_type_4</th>\n",
       "      <th>vehicle_type_5</th>\n",
       "      <th>contributing_factor_1</th>\n",
       "      <th>contributing_factor_2</th>\n",
       "      <th>contributing_factor_3</th>\n",
       "      <th>contributing_factor_4</th>\n",
       "      <th>contributing_factor_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4455765</td>\n",
       "      <td>2021-09-11 02:39:00</td>\n",
       "      <td>2021</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Aggressive Driving/Road Rage</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4513547</td>\n",
       "      <td>2022-03-26 11:45:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Pavement Slippery</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4675373</td>\n",
       "      <td>2023-11-01 01:29:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11230</td>\n",
       "      <td>40.62179</td>\n",
       "      <td>-73.970024</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Moped</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4541903</td>\n",
       "      <td>2022-06-29 06:55:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Pick-up Truck</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Following Too Closely</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4566131</td>\n",
       "      <td>2022-09-21 13:21:00</td>\n",
       "      <td>2022</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Station Wagon/Sport Utility Vehicle</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Passing Too Closely</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collision_id      crash_datetime  year   borough zip_code  latitude  \\\n",
       "0       4455765 2021-09-11 02:39:00  2021   Unknown  Unknown       NaN   \n",
       "1       4513547 2022-03-26 11:45:00  2022   Unknown  Unknown       NaN   \n",
       "2       4675373 2023-11-01 01:29:00  2023  BROOKLYN    11230  40.62179   \n",
       "3       4541903 2022-06-29 06:55:00  2022   Unknown  Unknown       NaN   \n",
       "4       4566131 2022-09-21 13:21:00  2022   Unknown  Unknown       NaN   \n",
       "\n",
       "   longitude  coords_missing  coords_imputed  num_injured  num_killed  severe  \\\n",
       "0        NaN            True           False          2.0         0.0       1   \n",
       "1        NaN            True           False          1.0         0.0       1   \n",
       "2 -73.970024           False           False          1.0         0.0       1   \n",
       "3        NaN            True           False          0.0         0.0       0   \n",
       "4        NaN            True           False          0.0         0.0       0   \n",
       "\n",
       "                        vehicle_type_1 vehicle_type_2 vehicle_type_3  \\\n",
       "0                                Sedan          Sedan        Unknown   \n",
       "1                                Sedan        Unknown        Unknown   \n",
       "2                                Moped          Sedan          Sedan   \n",
       "3                                Sedan  Pick-up Truck        Unknown   \n",
       "4  Station Wagon/Sport Utility Vehicle        Unknown        Unknown   \n",
       "\n",
       "  vehicle_type_4 vehicle_type_5         contributing_factor_1  \\\n",
       "0        Unknown        Unknown  Aggressive Driving/Road Rage   \n",
       "1        Unknown        Unknown             Pavement Slippery   \n",
       "2        Unknown        Unknown                   Unspecified   \n",
       "3        Unknown        Unknown         Following Too Closely   \n",
       "4        Unknown        Unknown           Passing Too Closely   \n",
       "\n",
       "  contributing_factor_2 contributing_factor_3 contributing_factor_4  \\\n",
       "0           Unspecified               Unknown               Unknown   \n",
       "1               Unknown               Unknown               Unknown   \n",
       "2           Unspecified           Unspecified               Unknown   \n",
       "3           Unspecified               Unknown               Unknown   \n",
       "4           Unspecified               Unknown               Unknown   \n",
       "\n",
       "  contributing_factor_5  \n",
       "0               Unknown  \n",
       "1               Unknown  \n",
       "2               Unknown  \n",
       "3               Unknown  \n",
       "4               Unknown  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SELECT COLUMNS FOR CLEANED DATASET\n",
    "# =============================================================================\n",
    "\n",
    "# Define columns to keep\n",
    "columns_to_keep = [\n",
    "    # Identifiers\n",
    "    'collision_id',\n",
    "    'crash_datetime',\n",
    "    'year',\n",
    "    \n",
    "    # Location\n",
    "    'borough',\n",
    "    'zip_code',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'coords_missing',\n",
    "    'coords_imputed',\n",
    "    \n",
    "    # Injury counts (for reference)\n",
    "    'num_injured',\n",
    "    'num_killed',\n",
    "    \n",
    "    # Target\n",
    "    'severe',\n",
    "    \n",
    "    # Vehicle types (1-5)\n",
    "    'vehicle_type_1', 'vehicle_type_2', 'vehicle_type_3', \n",
    "    'vehicle_type_4', 'vehicle_type_5',\n",
    "    \n",
    "    # Contributing factors (1-5)\n",
    "    'contributing_factor_1', 'contributing_factor_2', 'contributing_factor_3',\n",
    "    'contributing_factor_4', 'contributing_factor_5'\n",
    "]\n",
    "\n",
    "df_clean = df[columns_to_keep].copy()\n",
    "\n",
    "print(f\"Cleaned dataset: {len(df_clean):,} rows × {len(df_clean.columns)} columns\")\n",
    "print(f\"\\nColumns: {list(df_clean.columns)}\")\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d737c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
